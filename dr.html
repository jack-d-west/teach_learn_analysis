<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Teach Data-Analytics</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            display: flex;
            flex-direction: column;
            min-height: 100vh;
        }
        header, footer {
            background-color: #333;
            color: white;
            text-align: center;
            padding: 1em 0;
        }
        main {
            flex-grow: 1;
            padding: 20px;
            text-align: center;
        }
        nav a {
            color: white;
            text-decoration: none;
            margin: 0 15px;
        }
    </style>
</head>
<body>
    <header>
        <h1>Dimensionality Reduction</h1>
        <nav>
            <a href="index.html">Home</a>
            <a href="pca.html">PCA</a>
            <a href="cca.html">Canonical Corelation Analysis</a>
            <a href="tsne.html">t-SNE</a>


        </nav>
    </header>
    <main>
        <section id="dimensionality-reduction">

    <p style="text-align: left;"><strong>Dimensionality Reduction</strong> is a technique used in data analysis to simplify complex datasets by reducing the number of variables (dimensions) while retaining as much relevant information as possible. By reducing dimensions, we make data easier to visualize, process, and interpret, especially when dealing with large datasets with many features.</p>

    <h3 style="text-align: left;">Why Dimensionality Reduction?</h3>
    <p style="text-align: left;">Imagine analyzing a dataset with hundreds of features. More features can sometimes lead to issues like increased computation time and even reduced accuracy due to noise and redundant information (the "curse of dimensionality"). Dimensionality reduction helps solve this by condensing the dataset into a smaller number of meaningful components.</p>

    <h3 style="text-align: left;">Popular Techniques for Dimensionality Reduction</h3>
    <ul style="text-align: left;">
        <li><strong>Principal Component Analysis (PCA)</strong></li>
        <li><strong>t-Distributed Stochastic Neighbor Embedding (t-SNE)</strong></li>
        <li><strong>Canonical Correlation Analysis (CCA) </strong></li>
    </ul>

    
    <h3 style="text-align: left;">Why Use Dimensionality Reduction?</h3>
    <p style="text-align: left;">Dimensionality reduction can improve model performance, simplify data visualization, and reveal hidden patterns, making it an invaluable tool in machine learning and data science. By reducing irrelevant or redundant information, it sharpens our focus on the most significant parts of the data.</p>
        </section>
    <section id="dimensionality-reduction-examples">
    <h2 style="text-align: left;">Real-Life Examples of Dimensionality Reduction</h2>

    <h3 style="text-align: left;">1. Image Compression</h3>
    <p style="text-align: left;">In medical imaging, techniques like <strong>PCA</strong> reduce file size by focusing on the most important image features, enabling faster storage and transmission without losing diagnostic details.</p>
    <img src="img13.png" alt="Description" title="height test" width="300" height="300">
    <h3 style="text-align: left;">2. Customer Segmentation in Retail</h3>
    <p style="text-align: left;">Retailers use <strong>t-SNE</strong> to simplify customer data, identifying key purchasing patterns for targeted marketing, like clusters of high-value customers.</p>
    <img src="img14.png" alt="Description" title="height test" width="300" height="300">
    <h3 style="text-align: left;">3. Facial Recognition</h3>
    <p style="text-align: left;">Facial recognition systems reduce high-dimensional image data to focus on essential features (e.g., eye distance, face shape), enhancing speed and accuracy.</p>
    <img src="img15.png" alt="Description" title="height test" width="300" height="300">
    <h3 style="text-align: left;">4. Document Classification</h3>
    <p style="text-align: left;">Text analytics platforms use <strong>LSA</strong> or <strong>PCA</strong> to condense large text corpuses into core topics, aiding in document classification and sentiment analysis.</p>
    <img src="img16.png" alt="Description" title="height test" width="300" height="300">
    <h3 style="text-align: left;">5. Recommender Systems</h3>
    <p style="text-align: left;">Streaming services analyze user behavior, reducing dimensionality to capture essential preference patterns, leading to more accurate and efficient recommendations.</p>
    <img src="img17.png" alt="Description" title="height test" width="300" height="300">
    <h3 style="text-align: left;">6. Stock Market Trends</h3>
    <p style="text-align: left;">Analysts use dimensionality reduction to distill high-dimensional stock data, focusing on key indicators to better forecast market trends.</p>
    <img src="img18.png" alt="Description" title="height test" width="300" height="300">
    <h3 style="text-align: left;">7. Genomic Data in Health</h3>
    <p style="text-align: left;">Researchers apply dimensionality reduction to genetic data to identify critical genes or markers, streamlining research for potential treatments and insights into diseases.</p>
    <img src="img19.png" alt="Description" title="height test" width="300" height="300">
    </section>


    </main>

    <footer>
        <p>&copy; 2024 Teach Data-Analytics by Jakadeer</p>
    </footer>
</body>
</html>
